@misc{achelis2001technical,
  title={Technical Analysis from A to Z},
  author={Achelis, Steven B},
  year={2001},
  publisher={McGraw Hill New York}
}

@book{tsay2005analysis,
  title={Analysis of financial time series},
  author={Tsay, Ruey S},
  year={2005},
  publisher={John wiley \& sons}
}

@article{5c7b6f25-ed11-3745-8118-935d66a8f3d3,
 ISSN = {09528385},
 URL = {http://www.jstor.org/stable/2341482},
 author = {G. Udny Yule},
 journal = {Journal of the Royal Statistical Society},
 number = {1},
 pages = {1--63},
 publisher = {[Wiley, Royal Statistical Society]},
 title = {Why do we Sometimes get Nonsense-Correlations between Time-Series?--A Study in Sampling and the Nature of Time-Series},
 urldate = {2023-12-11},
 volume = {89},
 year = {1926}
}

@misc{Harrington_2003, 
title={Fundamental vs. technical analysis}, 
url={https://rpc.cfainstitute.org/en/research/cfa-magazine/2003/fundamental-vs-technical-analysis}, 
journal={CFA Institute}, 
author={Harrington, Cynthia}, year={2003}} 

@article{TANG2022363,
title = {A survey on machine learning models for financial time series forecasting},
journal = {Neurocomputing},
volume = {512},
pages = {363-380},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S092523122201089X},
author = {Yajiao Tang and Zhenyu Song and Yulin Zhu and Huaiyu Yuan and Maozhang Hou and Junkai Ji and Cheng Tang and Jianqiang Li},
keywords = {Financial Time Series, Forecasting, Machine learning, Hybrid method},
abstract = {Financial time series (FTS) are nonlinear, dynamic and chaotic. The search for models to facilitate FTS forecasting has been highly pursued for decades. Despite major related challenges, there has been much interest in this topic, and many efforts to forecast financial market pricing and the average movement of various financial assets have been implemented. Researchers have applied different models based on computer science and economics to gain efficient information and earn money through financial market investment decisions. Machine learning (ML) methods are popular and successful algorithms applied in the FTS domain. This paper provides a timely review of ML’s adoption in FTS forecasting. The progress of FTS forecasting models using ML methods is systematically summarized by searching articles published from 2011 to 2021. Focusing on the analysis of ML methods applied to the theoretical basis and empirical application of FTS data forecasting, this paper provides a relevant reference for FTS forecasting and interdisciplinary fusion research against the background of computational intelligence and big data. The literature survey reveals that the most commonly used models for prediction involve long short-term memory (LSTM) and hybrid methods. The main contribution of this paper is not only building a systematic program to compare the merits and demerits of specific FTS forecasting models but also detecting the importance and differences of each model to help researchers and practitioners make good choices. In addition, the limitations to be addressed and future research directions of ML models’ adoption in FTS forecasting are identified.}
}

@book{thomsett2006getting,
  title={Getting started in fundamental analysis},
  author={Thomsett, Michael C},
  year={2006},
  publisher={John Wiley \& Sons}
}

@incollection{NARISETTY2020207,
title = {Chapter 4 - Bayesian model selection for high-dimensional data},
editor = {Arni S.R. {Srinivasa Rao} and C.R. Rao},
series = {Handbook of Statistics},
publisher = {Elsevier},
volume = {43},
pages = {207-248},
year = {2020},
booktitle = {Principles and Methods for Data Science},
issn = {0169-7161},
doi = {https://doi.org/10.1016/bs.host.2019.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0169716119300380},
author = {Naveen Naidu Narisetty},
keywords = {Bayesian variable selection, High-dimensional data, Model comparison, Bayesian computation},
abstract = {High-dimensional data, where the number of features or covariates can even be larger than the number of independent samples, are ubiquitous and are encountered on a regular basis by statistical scientists both in academia and in industry. A majority of the classical research in statistics dealt with the settings where there is a small number of covariates. Due to the modern advancements in data storage and computational power, the high-dimensional data revolution has significantly occupied mainstream statistical research. In gene expression datasets, for instance, it is not uncommon to encounter datasets with observations on at most a few hundred independent samples (subjects) and with information on tens or hundreds of thousands of genes per each sample. An important and common question that arises quickly is—“which of the available covariates are relevant to the outcome of interest?” This concerns the problem of variable selection (and more generally model selection) in statistics and data science. This chapter will provide an overview of some of the most well-known model selection methods along with some of the more recent methods. While frequentist methods will be discussed, Bayesian approaches will be given a more elaborate treatment. The frequentist framework for model selection is primarily based on penalization, whereas the Bayesian framework relies on prior distributions for inducing shrinkage and sparsity. The chapter treats the Bayesian framework in the light of objective and empirical Bayesian viewpoints as the priors in the high-dimensional setting are typically not completely based subjective prior beliefs. An important practical aspect of high-dimensional model selection methods is computational scalability which will also be discussed.}
}

@article{WAFI2015939,
title = {Fundamental Analysis Models in Financial Markets – Review Study},
journal = {Procedia Economics and Finance},
volume = {30},
pages = {939-947},
year = {2015},
note = {IISES 3rd and 4th Economics and Finance Conference},
issn = {2212-5671},
doi = {https://doi.org/10.1016/S2212-5671(15)01344-1},
url = {https://www.sciencedirect.com/science/article/pii/S2212567115013441},
author = {Ahmed. S. Wafi and Hassan Hassan and Adel Mabrouk},
keywords = {Fundamental Analysis, Discounted Dividend Models, Multipliers Models, Discounted Cash Flow Model, Residual Income Model},
abstract = {The purpose of this paper is an attempt to reach a better stock valuation model of the Fundamental Analysis Approach, by reviewing the theoretical foundations and literature reviews. By reviewing the theoretical foundations for each model of the fundamental analysis models, and sequentially beginning of the Discounted Dividend Model (DDM), through a Multiplier Models, and finally the Discounted Cash Flow Model (DCFM), we find that all these models have strengths, despite the lack of accuracy, because it is required financial efficiency market. Recently Ohlson (1995) stated the simulated benefit in the formulation of the Residual Income Model (RIM). The Ohlson Model identifies the relationship between stock values and accounting variables. By reviewing the literature reviews, in financial markets, we conclude that the best model that can be relied upon to predict stock value, that proved credibility in both emerging and developed markets, is Residual Income Model (RIM), which doesn’t require financial efficiency for its application.}
}

@misc{Seegmiller_2023, 
title={10 metrics to measure the financial efficiency of your organization}, 
url={https://www.venasolutions.com/blog/10-metrics-measure-financial-efficiency-your-organization#:~:text=Financial efficiency measures how successful,your organization is financially efficient.}, 
journal={Vena}, 
publisher={Vena Solutions}, 
author={Seegmiller, Tom}, 
year={2023}, 
month={Sep}
}

@book{murphy1999technical,
  title={Technical analysis of the financial markets: A comprehensive guide to trading methods and applications},
  author={Murphy, John J},
  year={1999},
  publisher={Penguin}
}

@book{rockefeller2019technical,
  title={Technical analysis for dummies},
  author={Rockefeller, Barbara},
  year={2019},
  publisher={John Wiley \& Sons}
}

@article{Akbilgic2014ANH,
title={A novel Hybrid RBF Neural Networks model as a forecaster},
author={Oguz Akbilgic and Hamparsum Bozdogan and Mehmet Erdal Balaban},
journal={Statistics and Computing},
year={2014},
volume={24},
pages={365-375},
url={https://api.semanticscholar.org/CorpusID:17764829}
}

@book{michalski2013machine,
  title={Machine learning: An artificial intelligence approach},
  author={Michalski, Ryszard Stanislaw and Carbonell, Jaime Guillermo and Mitchell, Tom M},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@ARTICLE{8259424,
  author={Dean, Jeff and Patterson, David and Young, Cliff},
  journal={IEEE Micro}, 
  title={A New Golden Age in Computer Architecture: Empowering the Machine-Learning Revolution}, 
  year={2018},
  volume={38},
  number={2},
  pages={21-29},
  doi={10.1109/MM.2018.112130030}
}

@article{Dean2019TheDL,
  title={The Deep Learning Revolution and Its Implications for Computer Architecture and Chip Design},
  author={Jeffrey Dean},
  journal={ArXiv},
  year={2019},
  volume={abs/1911.05289},
  url={https://api.semanticscholar.org/CorpusID:207930506}
}

@Inbook{Awad2015,
  author="Awad, Mariette
  and Khanna, Rahul",
  title="Machine Learning",
  bookTitle="Efficient Learning Machines: Theories, Concepts, and Applications for Engineers and System Designers",
  year="2015",
  publisher="Apress",
  address="Berkeley, CA",
  pages="1--18",
  abstract="(ML) is a branch of artificial intelligence that systematically applies algorithms to synthesize the underlying relationships among data and information. For example, ML systems can be trained on automatic speech recognition systems (such as iPhone's Siri) to convert acoustic information in a sequence of speech data into semantic structure expressed in the form of a string of words.",
  isbn="978-1-4302-5990-9",
  doi="10.1007/978-1-4302-5990-9_1",
  url="https://doi.org/10.1007/978-1-4302-5990-9_1"
}

@Techreport{Rosenblatt_1957_6098,
  author = {Rosenblatt, F.},
 address = {Ithaca, New York},
 institution = {Cornell Aeronautical Laboratory},
 month = {January},
 number = {85-460-1},
 title = {The perceptron - A perceiving and recognizing automaton},
 year = {1957},
 title_with_no_special_chars = {The Perceptron  A perceiving and recognizing automaton}
}

@book{ciaburro2018hand,
  title={Hands-On Machine Learning on Google Cloud Platform: Implementing smart and efficient analytics using Cloud ML Engine},
  author={Ciaburro, G. and Ayyadevara, V.K. and Perrier, A.},
  isbn={9781788398879},
  url={https://books.google.co.uk/books?id=nvBZDwAAQBAJ},
  year={2018},
  publisher={Packt Publishing}
}

@article{HANSEN1999345,
  title = {Threshold effects in non-dynamic panels: Estimation, testing, and inference},
  journal = {Journal of Econometrics},
  volume = {93},
  number = {2},
  pages = {345-368},
  year = {1999},
  issn = {0304-4076},
  doi = {https://doi.org/10.1016/S0304-4076(99)00025-1},
  url = {https://www.sciencedirect.com/science/article/pii/S0304407699000251},
  author = {Bruce E. Hansen},
  keywords = {Threshold regression, Panel data, Liquidity constraints, Investment, Non-standard distribution},
  abstract = {Threshold regression methods are developed for non-dynamic panels with individual-specific fixed effects. Least squares estimation of the threshold and regression slopes is proposed using fixed-effects transformations. A non-standard asymptotic theory of inference is developed which allows construction of confidence intervals and testing of hypotheses. The methods are applied to a 15-year sample of 565 US firms to test whether financial constraints affect investment decisions.}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@article{cortes1995support,
  title={Support-vector networks},
  author={Cortes, Corinna and Vapnik, Vladimir},
  journal={Machine learning},
  volume={20},
  pages={273--297},
  year={1995},
  publisher={Springer}
}


@ARTICLE{Cao2001184,
	author = {Cao, Lijuan and Tay, Francis E.H.},
	title = {Financial forecasting using Support Vector Machines},
	year = {2001},
	journal = {Neural Computing and Applications},
	volume = {10},
	number = {2},
	pages = {184 – 192},
	doi = {10.1007/s005210170010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035533512&doi=10.1007%2fs005210170010&partnerID=40&md5=4bb7f70dfe398f35d1a7c137511f3953},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 272}
}

@misc{sadrfaridpour2020amlsvm,
      title={AML-SVM: Adaptive Multilevel Learning with Support Vector Machines}, 
      author={Ehsan Sadrfaridpour and Korey Palmer and Ilya Safro},
      year={2020},
      eprint={2011.02592},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@book{wei2012svm,
  title={A SVM approach in forecasting the moving direction of Chinese stock indices},
  author={Wei, Zhongyuan},
  year={2012},
  publisher={Lehigh University}
}

@inproceedings{ho1995random,
  title={Random decision forests},
  author={Ho, Tin Kam},
  booktitle={Proceedings of 3rd international conference on document analysis and recognition},
  volume={1},
  pages={278--282},
  year={1995},
  organization={IEEE}
}

@article{breiman2001random,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@article{breiman1996bagging,
  title={Bagging predictors},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={24},
  pages={123--140},
  year={1996},
  publisher={Springer}
}