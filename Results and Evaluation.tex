\chapter{Results and Evaluation}
This chapter covers the overall evaluation of the products developed.
This includes a comparison and evaluation of the results produced by the models as well as a reflection of what could be done differently if the project were to start over.

\section{Results From the Univariate Implementation}
The Univariate implementation was only implemented on linear regression, random forest regression, and support vector regression.
This was because it was unlikely for the results of the univariate analysis to be of a high standard due to the complexity of inflation as such it was deemed unnecessary to implement any more models.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{LinearRegUni.png}
    \includegraphics[width=0.8\textwidth]{RandomForestUni.png}
    \includegraphics[width=0.8\textwidth]{SVRuni.png}
    \caption[Univariate Implementation of Linear Regression, Random Forest Regression, and Support Vector Regression.]{Univariate Implementation of Linear Regression, Random Forest Regression, and Support Vector Regression.}
    \label{fig:Univar}
\end{figure}
As expected, the results from attempting to predict inflation solely based on its history were extremely poor.
None of the three models implemented produced predictions that could be helpful in any capacity.
These results serve to cement the complexity of inflation and how it is affected by many outside factors, thus making it necessary to use a large range of relevant features in order to produce an accurate forecast.

\section{The Multivariate Models' Results}
\subsection{Linear Regression Model, Random Forest Regression Model, and Support Vector Regression Model Predictions}
The table of regression metrics in the previous chapter showed how the linear regression, random forest, and support vector regression algorithms all performed worse prediction methods than the mean of the data (as shown in the r-squared score).
Although this was a disappointing result, it was somewhat expected as inflation is an extremely complex variable and simpler algorithms will likely struggle to form an understanding of its properties.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{threemodelsres.png}
    \caption[A Comparison of the Predictions of Linear Regression, Random Forest Regression, and Support Vector Regression Models.]{A Comparison of the Predictions of Linear Regression, Random Forest Regression, and Support Vector Regression Models.}
    \label{fig:threemodelsres}
\end{figure}
Figure \ref{fig:threemodelsres} shows the predictions of each model compared to the actual normalised value of inflation (shown in black).
It can be seen that all three models struggle to accurately predict inflation.
Interestingly, around the 65th-70th month mark, all three models predict an increase in inflation where there is a decrease.
This could be due to a linear property indicating that inflation was likely to increase, however, possibly due to factors outside of the feature set, the increase was held off.

It was expected for linear regression to struggle in predicting inflation as the relationship between it and the other features is complex.
This was shown in the correlation matrix created that showed very little Pearson pairwise correlation between CPI and the other features.
Although it has to be said that despite linear regression not being expected to perform well, the predictions graph still outperformed random forest regression and support vector regression if the large outlier around month 70 is ignored.

Random forest models seemed to have a good reputation for predictions during the literature review yet still failed to provide an accurate prediction for inflation.
This is possibly due to the fact that each tree in the random forest model is trained on a random subset of the data.
This may not be a good method for predicting inflation as it is sequential data so training random sections of the data on different trees likely removes any temporal dependencies present in the original data.

Support Vector Regression (SVR) predicts data by creating a hyperplane.
However, it is difficult to fit a hyperplane on data with a high number of dimensions or lots of noise.
Both of these caveats apply to the dataset used to predict inflation as it contained many different features each likely to have noise of some kind such as price fluctuations.
Furthermore, although SVRs create a hyperplane they are still made to work on linearly separable data so if the data contains too many complexities and non-linear relationships then SVRs can encounter issues in providing accurate predictions.

Overall, these three models are likely inappropriate use for predicting inflation when using a complex dataset.

\subsection{LSTM Network Model Predictions}
According to the metric testing, the LSTM's results were an improvement upon the results of the previous three models, however, it still struggled to accurately predict inflation.
This is seen further in the graph comparing the LSTM's predictions to the actual values.
The predictions fail to predict the more erratic highs and lows of inflation, instead producing a much smoother curve.
This could potentially be due to the number of past values the LSTM is given.
As it stores 12 past values it may struggle to predict the sharp gains and losses of inflation.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{lstmtotal.png}
    \caption[Predictions from the LSTM Network Trained on the Entire Dataset.]{LSTM Network Trained on the Entire Dataset.}
    \label{fig:lstmtotal}
\end{figure}
The predictions from the model trained on the entire dataset, produce a smooth curve that follows the trends of inflation but fails to depict the magnitude and precision of the finer changes.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{lstm150.png}
    \caption[Predictions from the LSTM Network Trained on a subset of the Dataset.]{LSTM Network Trained on a subset of the Dataset.}
    \label{fig:lstm150}
\end{figure} 
The predictions of the LSTM trained on the subset of the data more accurately depict the small volatile increments but still fail to predict the magnitude of inflation.\\
The graph produced by the LSTM that was trained on the subset of the dataset is preferable to the graph produced by the LSTM trained on the entire dataset.
However, neither model produces close accurate predictions of the actual value of inflation.
Both LSTMs can follow the trends of inflation (although somewhat delayed) but struggle to produce predictions that are of the correct magnitude.

\subsection{Feedforward Neural Network Predictions}
Of the models implemented, the FNN produced the best results.
This model, like the others, was implemented on both the whole dataset and a subset of the original data that did not include values from before the 1980s.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{anntotal.png}
    \caption[Predictions from the Feedforward Neural-Network Trained on the Entire Dataset.]{Neural-Network Trained on the Entire Dataset.}
    \label{fig:anntotal}
\end{figure}
The predictions from the model trained on the entire dataset start well but lose accuracy towards the end of the training set.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{ann150.png}
    \caption[Predictions from the Feedforward Neural-Network Trained on a subset of the Dataset.]{Neural-Network Trained on a subset of the Dataset.}
    \label{fig:ann150}
\end{figure} 

Figures \ref{fig:anntotal} and \ref{fig:ann150} show the results produced by the model with the entire data vs the subset of the data respectively.
The figures show how the models trained on the subset of the dataset produced more accurate predictions than the models trained on the entire dataset.

\subsection{Why the Feedforward Neural Network Had the Most Success}
The artificial neural network shown in figure \ref{fig:ann150} produced the best results out of all of the models implemented to predict inflation.
This is likely due to several factors.

\subsubsection{Removing Data Outliers}
This method was applied to all models successfully.
The first 150 samples of CPI contained large outliers compared to the rest of the dataset.
Including these samples would have negatively affected the model's predictive abilities.
This was confirmed by the fact that the other models also showed an increase in performance after the first 150 rows of data were removed.

\subsubsection{Hyperparameter Tuning}
Another reason for the FNN's success is that it was the most flexible of the models with the largest number of hyperparameters that could be adjusted.
The only other model that underwent similar hyperparameter tuning was the LSTM and interestingly the hyperparameters that were found to be optimal were similar for both models.  
However, some of the hyperparameters found to be optimal by the grid search were somewhat unexpected.\\
The model performed best with 128 nodes in the hidden layer, which was the highest option in the grid and higher than expected.
The reason for the model preferring a higher number of nodes could be that with more nodes the model could better capture the problems' more intricate non-linear patterns.
However, such a large number of nodes comes at a computational cost as it will require more processing power and take more time to run the model.\\
The preferred dropout rate was 0\% meaning that it is quite unlikely the model came close to overtraining as if it did the model would have been more successful with a higher dropout rate.
Another possibility is that the other dropout rates available in the grid were already too high and dropouts were occurring too often.
The next smallest dropout rate available was 10\% or 0.1 so this theory is unlikely as 0.1 is considered relatively low.\\
The ideal learning rate was 0.005 which was unexpected as s it is higher than Keras' default learning rate of 0.001.
A higher learning rate often allows for faster convergence but can lead to the model oscillating or diverging if it overshoots the optimal point.
Despite this, it does not seem like the model oscillated or diverged based on the loss graph as it did not display any additional inflections.\\
The final hyperparameter was a batch size of 8, this was the smallest batch size option.
The batch size dictates the number of data samples the model works through before it updates its internal parameters.
Thus a smaller batch size means that the model's parameters are being updated more frequently.
Research\cite{masters2018revisiting} indicates that smaller batch sizes produce models with better generalisation.
This can even be true for models trained using mini-batch sizes as small as 2.
A model that updates its parameters more frequently is likely to perform well on data that has a lot of complex relationships.
Therefore, the fact that the smallest batch size produced the best results is not surprising as the data the model is training on likely contains many such relationships.\\

\subsubsection{Recurrent Neural Networks vs None Recurrent Neural Networks}
The previously mentioned factors still do not explain why the feedforward network produced superior results to the LSTM.
During the 'Expected Model Performance' section of this report, the LSTM had been predicted to produce the best results.
This prediction was made on the basis that an LSTM has the ability to retain historical data and use it in conjunction with present data in order to tune its parameters.
Having this ability should in theory make the LSTM better suited for utilising the sequential time series data that made up the dataset for this project.
However, as shown in the results of both the metrics and graphs presented, the LSTM performed worse than a non-recurrent network: the feedforward neural network.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{annvslstm.png}
    \caption[A Comparison of the LSTM and FNN Predictions.]{A Comparison of the LSTM and FNN Predictions.}
    \label{fig:annvslstm}
\end{figure} 
One explanation for the poor performance of the recurrent neural network is covered in a quote from Justin Sirignano and Rama Cont, which states:
"financial data can be 'non-stationary' and prone to regime changes which may render older data less relevant for prediction"\cite{sirignano2018universal}.
This means that outside factors can have an effect on the value of financial data.
In the context of this project, this could mean that outside variables that were not included in the feature set impacted inflation which would lead the LSTM to struggle in predicting inflation's value.
However, if this was the case then the feedforward network should have struggled to form accurate predictions in certain areas as well.
Furthermore, the features in the dataset cover a wide range of macroeconomic indicators that should exhibit changes in the case of an outside event occurring.
Finally, there was no obvious indication in the graph comparison between inflation and the LSTM's results that a regime change had taken place.
A regime change would have been represented in dips or spikes in inflation that were not represented in the LSTM's results. 
So it is unlikely that the sole reason for poor performance from the LSTM is due to outside features.

Another explanation is that the problem of forecasting inflation is less sequential than it was initially thought to be.
LSTMs are made to forecast sequential data and time series data, but what if the value of inflation does not rely heavily on past values?
It may seem a strange hypothesis but it could potentially mean that each value of inflation is almost independent of the last value within reason.
LSTMs are a popular choice of recurrent neural network because of their ability to recognise long-term dependencies, but if inflation's value does not rely heavily on long-term temporal dependencies then this ability will not be useful.
An LSTM's recurrent nature can impede its performance if the target does not show any patterns relating to long-term dependencies.
LSTMs take longer to train than standard feedforward networks and require more computational power due to their recurrent nature.
Using non-sequential data on an LSTM may also hinder its predictive ability as LSTMs assume long-term relationships exist in the data so the model will be looking for relationships that do not exist.

Sirignano and Cont solve all of the performance problems of their LSTM with one solution: lots of data.



% %TODO
% - continue writing why the ann was the best. How is it better than an lstm?
% - is this the same as what was predicted
% - what could be improved next time?
% - granger test function using pseudocode/algorithm in design.tex

