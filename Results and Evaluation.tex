\chapter{Results and Evaluation}
This chapter covers the overall evaluation of the products developed.
This includes a comparison and evaluation of the results produced by the models as well as a reflection of what could be done differently if the project were to start over.


\section{Results From the Univariate Implementation}
The Univariate implementation was only implemented on linear regression, random forest regression, and support vector regression.
This was because it was unlikely for the results of the univariate analysis to be of a high standard due to the complexity of inflation as such it was deemed unnecessary to implement any more models.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{LinearRegUni.png}
    \includegraphics[width=0.8\textwidth]{RandomForestUni.png}
    \includegraphics[width=0.8\textwidth]{SVRuni.png}
    \caption[Univariate Implementation of Linear Regression, Random Forest Regression, and Support Vector Regression.]{Univariate Implementation of Linear Regression, Random Forest Regression, and Support Vector Regression.}
    \label{fig:Univar}
\end{figure}
As expected, the results from attempting to predict inflation solely based on its history were extremely poor.
None of the three models implemented produced predictions that could be helpful in any capacity.
These results serve to cement the complexity of inflation and how it is affected by many outside factors, thus making it necessary to use a large range of relevant features in order to produce an accurate forecast.

\section{The Multivariate Models' Results}
\subsection{Linear Regression Model, Random Forest Regression Model, and Support Vector Regression Model Predictions}
The table of regression metrics in the previous chapter showed how the linear regression, random forest, and support vector regression algorithms all performed worse prediction methods than the mean of the data (as shown in the r-squared score).
Although this was a disappointing result, it was somewhat expected as inflation is an extremely complex variable and simpler algorithms will likely struggle to form an understanding of its properties.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{threemodelsres.png}
    \caption[A Comparison of the Predictions of Linear Regression, Random Forest Regression, and Support Vector Regression Models.]{A Comparison of the Predictions of Linear Regression, Random Forest Regression, and Support Vector Regression Models.}
    \label{fig:threemodelsres}
\end{figure}
Figure \ref{fig:threemodelsres} shows the predictions of each model compared to the actual normalised value of inflation (shown in black).
It can be seen that all three models struggle to accurately predict inflation.
Interestingly, around the 65th-70th month mark, all three models predict an increase in inflation where there is a decrease.
This could be due to a linear property indicating that inflation was likely to increase, however, possibly due to factors outside of the feature set, the increase was held off.

It was expected for linear regression to struggle in predicting inflation as the relationship between it and the other features is complex.
This was shown in the correlation matrix created that showed very little Pearson pairwise correlation between CPI and the other features.
Although it has to be said that despite linear regression not being expected to perform well, the predictions graph still outperformed random forest regression and support vector regression if the large outlier around month 70 is ignored.

Random forest models seemed to have a good reputation for predictions during the literature review yet still failed to provide an accurate prediction for inflation.
This is possibly due to the fact that each tree in the random forest model is trained on a random subset of the data.
This may not be a good method for predicting inflation as it is sequential data so training random sections of the data on different trees likely removes any temporal dependencies present in the original data.

Support Vector Regression (SVR) predicts data by creating a hyperplane.
However, it is difficult to fit a hyperplane on data with a high number of dimensions or lots of noise.
Both of these caveats apply to the dataset used to predict inflation as it contained many different features each likely to have noise of some kind such as price fluctuations.
Furthermore, although SVRs create a hyperplane they are still made to work on linearly separable data so if the data contains too many complexities and non-linear relationships then SVRs can encounter issues in providing accurate predictions.

Overall, these three models are likely inappropriate use for predicting inflation when using a complex dataset.

\subsection{LSTM Network Model Predictions}
According to the metric testing, the LSTM's results were an improvement upon the results of the previous three models, however, it still struggled to accurately predict inflation.
This is seen further in the graph comparing the LSTM's predictions to the actual values.
The predictions fail to predict the more erratic highs and lows of inflation, instead producing a much smoother curve.
This could potentially be due to the number of past values the LSTM is given.
As it stores 12 past values it may struggle to predict the sharp gains and losses of inflation.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{lstmtotal.png}
    \caption[Predictions from the LSTM Network Trained on the Entire Dataset.]{LSTM Network Trained on the Entire Dataset.}
    \label{fig:lstmtotal}
\end{figure}
The predictions from the model trained on the entire dataset, produce a smooth curve that follows the trends of inflation but fails to depict the magnitude and precision of the finer changes.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{lstm150.png}
    \caption[Predictions from the LSTM Network Trained on a subset of the Dataset.]{LSTM Network Trained on a subset of the Dataset.}
    \label{fig:lstm150}
\end{figure} 
The predictions of the LSTM trained on the subset of the data more accurately depict the small volatile increments but still fail to predict the magnitude of inflation.\\
The graph produced by the LSTM that was trained on the subset of the dataset is preferable to the graph produced by the LSTM trained on the entire dataset.
However, neither model produces close accurate predictions of the actual value of inflation.
Both LSTMs can follow the trends of inflation (although somewhat delayed) but struggle to produce predictions that are of the correct magnitude.

\subsection{Aritficial Neural Network Predictions}
Of the models implemented, the custom ANN produced the best results.
This model, like the others, was implemented on both the whole dataset and a subset of the original data that did not include values from before the 1980s.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{anntotal.png}
    \caption[Predictions from the Artificial Neural-Network Trained on the Entire Dataset.]{Neural-Network Trained on the Entire Dataset.}
    \label{fig:anntotal}
\end{figure}
The predictions from the model trained on the entire dataset start well but lose accuracy towards the end of the training set.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{ann150.png}
    \caption[Predictions from the Artificial Neural-Network Trained on a subset of the Dataset.]{Neural-Network Trained on a subset of the Dataset.}
    \label{fig:ann150}
\end{figure} 

Figures \ref{fig:anntotal} and \ref{fig:ann150} show the results produced by the model with the entire data vs the subset of the data respectively.
The figures show how the models trained on the subset of the dataset produced more accurate predictions than the models trained on the entire dataset.

% %TODO
% - compare the results of each model
% - which was best, which was worst
% - is this the same as was predicted?
% - why did the good ones do good and the bad do bad
% - what could be improved next time?
% - why does random forest do bad? Each tree is trained on a RANDOM subset of the data (not good for sequential)
% - why does SVR do bad? Trys to fit a hyperplane of best fit, this might not be possible if the datas relationships has more then 3 dimensions
% - why does linear regression do bad? there are no linear relationships


\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{annvslstm.png}
    \caption[A Comparison of the LSTM and ANN Predictions.]{A Comparison of the LSTM and ANN Predictions.}
    \label{fig:annvslstm}
\end{figure} 
